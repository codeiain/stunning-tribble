version: '3.3'

volumes:
    prometheus_data: {}
    grafana_data: {}
    elasticsearch: {}
    redis:
        driver: local

services:
    mediawiki:
        container_name: wiki
        image: mediawiki
        restart: always
        ports:
            - 80:80
        links:
            - database
        volumes:
            - type: build
              source: ./infra/mediawiki/LocalSettings.php
              target: /var/www/html/LocalSettings.php

            - ./infra/mediawiki/images:/var/www/html/images
            # After initial setup, download LocalSettings.php to the same directory as
            # this yaml and uncomment the following line and use compose to restart
            # the mediawiki service
            - ./infra/mediawiki/LocalSettings.php:/var/www/html/LocalSettings.php
    alertmanager:
        image: prom/alertmanager
        ports:
        - 9093:9093
        volumes:
        - "./infra/alertmanager/:/etc/alertmanager/"
        command:
        - '--config.file=/etc/alertmanager/config.yml'
        - '--storage.path=/alertmanager'
        deploy:
            placement:
                constraints:
                - node.role==manager
            restart_policy:
                condition: on-failure   

    database:
        image: mariadb
        container_name: db
        restart: always
        ports:
            - 3306:3306
        environment:
            # @see https://phabricator.wikimedia.org/source/mediawiki/browse/master/includes/DefaultSettings.php
            MYSQL_RANDOM_ROOT_PASSWORD: 0
            MYSQL_DATABASE: my_wiki
            MYSQL_USER: wikiuser 
            MYSQL_PASSWORD: example
        volumes:
            - ./infra/mysql/data:/var/lib/mysql
    # mobileapp:
    #     tty: true
    #     build: 
    #         context: mobile-client
    #         dockerfile: Dockerfile
    #     ports:
    #         - 8100:8100
    #     restart: always
    #     depends_on:
    #         - redis
    #         - prometheus
    #         - grafana

    playercacheserver:
        tty: true
        build: 
            context: player-cache-server
            dockerfile: Dockerfile
        ports:
            - 8011:8011
        restart: always
        depends_on:
            - redis
            - prometheus
            - grafana
    playerserver:
        tty: true
        build: 
            context: player-server
            dockerfile: Dockerfile
        ports:
            - 8010:8010
            - 9009:9009
        restart: always
        depends_on:
            - couchbase
            - prometheus
            - grafana

    mapserver:
        tty: true
        build: 
            context: map-server
            dockerfile: Dockerfile
        ports:
            - 8000:8000
        restart: always
        depends_on:
            - couchbase
            - prometheus
            - grafana
    
    websocketgateway:
        tty: true
        build: 
            context: websocket-gateway
            dockerfile: Dockerfile
        ports:
            - 8001:8001
        restart: always
        depends_on:
            - couchbase
            - prometheus
            - grafana

    sonarcouldexporter:
        tty: true
        image: whyeasy/sonarcloud-exporter:latest
        ports:
            - 9999:9999
        restart: always
        environment:
            - SC_ORGANIZATION=codeiain-1
            - SC_TOKEN=20c1374022ed254e996e3f0dd90ff64b5bb92b3e
            - LISTEN_ADDRESS=9999
        depends_on:
            - prometheus
            - grafana

    couchbase:
        tty: true
        image: couchbase/server
        deploy:
            replicas: 1
        restart: always
        ports:
            - 8091:8091
            - 8092:8092
            - 8093:8093
            - 8094:8094
            - 11210:11210
        volumes:
            - "./setup-couchbase.sh:/opt/couchbase/setup-couchbase.sh"
            - "./mapTestData.json:/opt/couchbase/mapTestData.json"
        command: 
            - /opt/couchbase/setup-couchbase.sh
    redis:
        image: redis:6.2-alpine
        restart: always
        ports:
            - '6379:6379'
        command: redis-server --save 20 1 --loglevel warning --requirepass eYVX7EwVmmxKPCDmwMtyKVge8oLd2t81
        volumes: 
            - redis:/data
    redisexporter:
        image: oliver006/redis_exporter
        restart: always
        ports:
          - '9121:9121'
        environment:
          - REDIS_ADDR=redis://redis:6379
          - REDIS_PASSWORD=eYVX7EwVmmxKPCDmwMtyKVge8oLd2t81

    prometheus:
        image: prom/prometheus
        volumes:
            - ./infra/prometheus/:/etc/prometheus/
            - prometheus_data:/prometheus
        command:
            - '--config.file=/etc/prometheus/prometheus.yml'
            - '--storage.tsdb.path=/prometheus'
            - '--web.console.libraries=/usr/share/prometheus/console_libraries'
            - '--web.console.templates=/usr/share/prometheus/consoles'
            - '--web.enable-lifecycle'
            - '--web.enable-admin-api'
        ports:
            - 9090:9090
        depends_on:
            - cadvisor
    #      - pushgateway
        deploy:
            placement:
                constraints:
                    - node.role==manager
            restart_policy:
                condition: on-failure

    cadvisor:
        image: gcr.io/cadvisor/cadvisor
        volumes:
            - /:/rootfs:ro
            - /var/run:/var/run:rw
            - /sys:/sys:ro
            - /var/lib/docker/:/var/lib/docker:ro
        ports:
            - 8080:8080
        deploy:
            mode: global
            restart_policy:
                condition: on-failure
    grafana:
        image: grafana/grafana
        depends_on:
            - prometheus
        ports:
            - 3000:3000
        environment:
            - GF_INSTALL_PLUGINS=flant-statusmap-panel,grafana-polystat-panel,snuids-radar-panel
        volumes:
            - ./infra/grafana/provisioning/:/etc/grafana/provisioning/
        env_file:
            - ./infra/grafana/config.monitoring
        user: "472"
        deploy:
            placement:
                constraints:
                - node.role==manager
            restart_policy:
                condition: on-failure

                